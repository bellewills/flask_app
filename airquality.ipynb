{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26c949f3-5629-486b-aaa7-25ff169cd29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /Users/bellewills/anaconda3/envs/flaskenv/lib/python3.12/site-packages (1.6.14)\n",
      "Requirement already satisfied: six>=1.10 in /Users/bellewills/anaconda3/envs/flaskenv/lib/python3.12/site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in /Users/bellewills/anaconda3/envs/flaskenv/lib/python3.12/site-packages (from kaggle) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil in /Users/bellewills/anaconda3/envs/flaskenv/lib/python3.12/site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in /Users/bellewills/anaconda3/envs/flaskenv/lib/python3.12/site-packages (from kaggle) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /Users/bellewills/anaconda3/envs/flaskenv/lib/python3.12/site-packages (from kaggle) (4.66.4)\n",
      "Requirement already satisfied: python-slugify in /Users/bellewills/anaconda3/envs/flaskenv/lib/python3.12/site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: urllib3 in /Users/bellewills/anaconda3/envs/flaskenv/lib/python3.12/site-packages (from kaggle) (2.2.1)\n",
      "Requirement already satisfied: bleach in /Users/bellewills/anaconda3/envs/flaskenv/lib/python3.12/site-packages (from kaggle) (4.1.0)\n",
      "Requirement already satisfied: packaging in /Users/bellewills/anaconda3/envs/flaskenv/lib/python3.12/site-packages (from bleach->kaggle) (23.2)\n",
      "Requirement already satisfied: webencodings in /Users/bellewills/anaconda3/envs/flaskenv/lib/python3.12/site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /Users/bellewills/anaconda3/envs/flaskenv/lib/python3.12/site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/bellewills/anaconda3/envs/flaskenv/lib/python3.12/site-packages (from requests->kaggle) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/bellewills/anaconda3/envs/flaskenv/lib/python3.12/site-packages (from requests->kaggle) (3.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#install Kaggle Command Line Tool to use on Jupyter Notebook -here-\n",
    "%pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3145f9c4-dbad-4ba3-a6bb-1b79f86fa0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle API 1.6.14\n"
     ]
    }
   ],
   "source": [
    "#verify it works\n",
    "!kaggle --version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3616d161-f0f9-4ed9-b34a-8435f7479c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: kaggle [-h] [-v]\n",
      "              {competitions,c,datasets,d,kernels,k,models,m,files,f,config}\n",
      "              ...\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  -v, --version         show program's version number and exit\n",
      "\n",
      "commands:\n",
      "  {competitions,c,datasets,d,kernels,k,models,m,files,f,config}\n",
      "                        Use one of:\n",
      "                        competitions {list, files, download, submit, submissions, leaderboard}\n",
      "                        datasets {list, files, download, create, version, init, metadata, status}\n",
      "                        kernels {list, files, init, push, pull, output, status}\n",
      "                        models {instances, get, list, init, create, delete, update}\n",
      "                        models instances {versions, get, files, init, create, delete, update}\n",
      "                        models instances versions {init, create, download, delete, files}\n",
      "                        config {view, set, unset}\n",
      "    competitions (c)    Commands related to Kaggle competitions\n",
      "    datasets (d)        Commands related to Kaggle datasets\n",
      "    kernels (k)         Commands related to Kaggle kernels\n",
      "    models (m)          Commands related to Kaggle models\n",
      "    files (f)           Commands related files\n",
      "    config              Configuration settings\n"
     ]
    }
   ],
   "source": [
    "#check commands you can use\n",
    "!kaggle --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a0544e2-1061-4dbb-8a14-464098440d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: kaggle datasets [-h]\n",
      "                       {list,files,download,create,version,init,metadata,status}\n",
      "                       ...\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "\n",
      "commands:\n",
      "  {list,files,download,create,version,init,metadata,status}\n",
      "    list                List available datasets\n",
      "    files               List dataset files\n",
      "    download            Download dataset files\n",
      "    create              Create a new dataset\n",
      "    version             Create a new dataset version\n",
      "    init                Initialize metadata file for dataset creation\n",
      "    metadata            Download metadata about a dataset\n",
      "    status              Get the creation status for a dataset\n"
     ]
    }
   ],
   "source": [
    "#view datasets comman\n",
    "!kaggle datasets -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1384eda-d616-4665-9b1a-cc7b039fc85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: kaggle datasets list [-h] [--sort-by SORT_BY] [--size SIZE]\n",
      "                            [--file-type FILE_TYPE] [--license LICENSE_NAME]\n",
      "                            [--tags TAG_IDS] [-s SEARCH] [-m] [--user USER]\n",
      "                            [-p PAGE] [-v] [--max-size MAX_SIZE]\n",
      "                            [--min-size MIN_SIZE]\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --sort-by SORT_BY     Sort list results. Default is 'hottest'. Valid options are 'hottest', 'votes', 'updated', and 'active'\n",
      "  --size SIZE           DEPRECATED. Please use --max-size and --min-size to filter dataset sizes.\n",
      "  --file-type FILE_TYPE\n",
      "                        Search for datasets with a specific file type. Default is 'all'. Valid options are 'all', 'csv', 'sqlite', 'json', and 'bigQuery'. Please note that bigQuery datasets cannot be downloaded\n",
      "  --license LICENSE_NAME\n",
      "                        Search for datasets with a specific license. Default is 'all'. Valid options are 'all', 'cc', 'gpl', 'odb', and 'other'\n",
      "  --tags TAG_IDS        Search for datasets that have specific tags. Tag list should be comma separated\n",
      "  -s SEARCH, --search SEARCH\n",
      "                        Term(s) to search for\n",
      "  -m, --mine            Display only my items\n",
      "  --user USER           Find public datasets owned by a specific user or organization\n",
      "  -p PAGE, --page PAGE  Page number for results paging. Page size is 20 by default\n",
      "  -v, --csv             Print results in CSV format (if not set print in table format)\n",
      "  --max-size MAX_SIZE   Specify the maximum size of the dataset to return (bytes)\n",
      "  --min-size MIN_SIZE   Specify the minimum size of the dataset to return (bytes)\n"
     ]
    }
   ],
   "source": [
    "#list available commands to search for dataset\n",
    "!kaggle datasets list -h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45110ac8-607d-4fa4-a7c4-2b7c73018303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401 - Unauthorized - Unauthenticated\n"
     ]
    }
   ],
   "source": [
    "# Search datasets\n",
    "!kaggle datasets list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a649dee-1a42-4443-964a-94dd0d72fa52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401 - Unauthorized - Unauthenticated\n"
     ]
    }
   ],
   "source": [
    "# Search datasets for aqi or air quality\n",
    "!kaggle datasets list -s aqi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "686e5420-97dd-4780-8320-4dfb87dcbbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name            size  creationDate         \n",
      "-------------  -----  -------------------  \n",
      "data_date.csv  427KB  2024-06-06 08:52:50  \n"
     ]
    }
   ],
   "source": [
    "#use !kaggle datasets files <owner>/<dataset-name> \n",
    "\n",
    "!kaggle datasets files azminetoushikwasi/aqi-air-quality-index-scheduled-daily-update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30a12cc0-b1d7-4b95-bedb-5b1cb59bba5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: kaggle datasets download [-h] [-f FILE_NAME] [-p PATH] [-w] [--unzip]\n",
      "                                [-o] [-q]\n",
      "                                [dataset]\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  dataset               Dataset URL suffix in format <owner>/<dataset-name> (use \"kaggle datasets list\" to show options)\n",
      "  -f FILE_NAME, --file FILE_NAME\n",
      "                        File name, all files downloaded if not provided\n",
      "                        (use \"kaggle datasets files -d <dataset>\" to show options)\n",
      "  -p PATH, --path PATH  Folder where file(s) will be downloaded, defaults to current working directory\n",
      "  -w, --wp              Download files to current working path\n",
      "  --unzip               Unzip the downloaded file. Will delete the zip file when completed.\n",
      "  -o, --force           Skip check whether local version of file is up to date, force file download\n",
      "  -q, --quiet           Suppress printing information about the upload/download progress\n"
     ]
    }
   ],
   "source": [
    "#look at download options \n",
    "!kaggle datasets download -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52f4963c-3046-4df2-b657-1fd385e44a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/azminetoushikwasi/aqi-air-quality-index-scheduled-daily-update\n",
      "License(s): ODbL-1.0\n",
      "Downloading data_date.csv to /Users/bellewills/flask_app\n",
      "... resuming from 428160 bytes (9160 bytes left) ...\n",
      " 98%|██████████████████████████████████████████████▉ | 418k/427k [00:00<?, ?B/s]\n",
      "100%|████████████████████████████████████████| 427k/427k [00:00<00:00, 5.73MB/s]\n"
     ]
    }
   ],
   "source": [
    "#download specific file\n",
    "!kaggle datasets download azminetoushikwasi/aqi-air-quality-index-scheduled-daily-update -f data_date.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5801fe1-948d-4fa3-8dd3-7a23393b18c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/bellewills/anaconda3/envs/flaskenv/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/bellewills/anaconda3/envs/flaskenv/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/bellewills/anaconda3/envs/flaskenv/lib/python3.12/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/bellewills/anaconda3/envs/flaskenv/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/bellewills/anaconda3/envs/flaskenv/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/bellewills/anaconda3/envs/flaskenv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ac94efc-f55c-4343-8269-aaeb010470f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Country</th>\n",
       "      <th>Status</th>\n",
       "      <th>AQI Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Good</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>Angola</td>\n",
       "      <td>Unhealthy for Sensitive Groups</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13247</th>\n",
       "      <td>2024-06-06</td>\n",
       "      <td>Uzbekistan</td>\n",
       "      <td>Good</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13248</th>\n",
       "      <td>2024-06-06</td>\n",
       "      <td>Vatican</td>\n",
       "      <td>Good</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13249</th>\n",
       "      <td>2024-06-06</td>\n",
       "      <td>Venezuela</td>\n",
       "      <td>Good</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13250</th>\n",
       "      <td>2024-06-06</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13251</th>\n",
       "      <td>2024-06-06</td>\n",
       "      <td>Zambia</td>\n",
       "      <td>Unhealthy for Sensitive Groups</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13252 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date     Country                          Status  AQI Value\n",
       "0      2022-07-21     Albania                            Good         14\n",
       "1      2022-07-21     Algeria                        Moderate         65\n",
       "2      2022-07-21     Andorra                        Moderate         55\n",
       "3      2022-07-21      Angola  Unhealthy for Sensitive Groups        113\n",
       "4      2022-07-21   Argentina                        Moderate         63\n",
       "...           ...         ...                             ...        ...\n",
       "13247  2024-06-06  Uzbekistan                            Good         21\n",
       "13248  2024-06-06     Vatican                            Good         25\n",
       "13249  2024-06-06   Venezuela                            Good         10\n",
       "13250  2024-06-06     Vietnam                        Moderate         63\n",
       "13251  2024-06-06      Zambia  Unhealthy for Sensitive Groups        140\n",
       "\n",
       "[13252 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "aqi = pd.read_csv(\"data_date.csv\")\n",
    "aqi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "886811d7-db58-4770-92ff-0173152a3f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install sql\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e679b79d-3b7d-4357-bba5-5b0b6cecd29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create database called \"aqi.db\"\n",
    "db_connect = sqlite3.connect('aqi.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2984275-f265-4ac2-9843-9966e0930aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cur (cursors) allow us the execute sql queries! \n",
    "cur = db_connect.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f41aab5-cfd4-49be-8959-5c87e0687f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x109ac96c0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create table \"aqitable\" with composite unique constraint\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS aqitable (\n",
    "        ID INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        Date DATETIME NOT NULL,\n",
    "        Country TEXT,\n",
    "        Status TEXT,\n",
    "        AQI_Value INTEGER,\n",
    "        UNIQUE(Date, Country)\n",
    "    )\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d20ebcb0-8e83-434b-b814-d5eebfd50edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('aqitable',), ('sqlite_sequence',)]\n"
     ]
    }
   ],
   "source": [
    "#show all new tables in new SQL database \n",
    "cur.execute (\"SELECT name from sqlite_master where type='table' order by name;\")\n",
    "results = cur.fetchall()\n",
    "print(results) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e36fa1f-649f-4277-9c29-1e90085fbc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas allow to run SQL querry and save data \n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ba47ea7-10fc-4ce0-9d29-2b24b67e7d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13252"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Put AQI dataset we found into our sql data as aqi \n",
    "aqi.to_sql('aqitable', db_connect, if_exists='replace', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de4159f4-1172-41ae-aee9-d3f604529291",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query sql tabke inty pythin pandas dataframe\n",
    "latest_aqi = pd.read_sql_query('select * from aqitable limit 100', db_connect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "675acd4a-6863-4095-b536-7a30d35991be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Country</th>\n",
       "      <th>Status</th>\n",
       "      <th>AQI Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Good</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>Angola</td>\n",
       "      <td>Unhealthy for Sensitive Groups</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>New Caledonia</td>\n",
       "      <td>Good</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>Good</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>Nigeria</td>\n",
       "      <td>Unhealthy for Sensitive Groups</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>Norway</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date        Country                          Status  AQI Value\n",
       "0   2022-07-21        Albania                            Good         14\n",
       "1   2022-07-21        Algeria                        Moderate         65\n",
       "2   2022-07-21        Andorra                        Moderate         55\n",
       "3   2022-07-21         Angola  Unhealthy for Sensitive Groups        113\n",
       "4   2022-07-21      Argentina                        Moderate         63\n",
       "..         ...            ...                             ...        ...\n",
       "95  2022-07-21    Netherlands                        Moderate         70\n",
       "96  2022-07-21  New Caledonia                            Good         15\n",
       "97  2022-07-21    New Zealand                            Good         18\n",
       "98  2022-07-21        Nigeria  Unhealthy for Sensitive Groups        105\n",
       "99  2022-07-21         Norway                        Moderate         73\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view latest aqi data\n",
    "latest_aqi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e62b087a-8320-4505-b7aa-f7ad5f59239e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AQI DataFrame columns: Index(['Date', 'Country', 'Status', 'AQI Value'], dtype='object')\n",
      "Weather DataFrame columns: Index(['country', 'location_name', 'latitude', 'longitude', 'timezone',\n",
      "       'last_updated_epoch', 'last_updated', 'temperature_celsius',\n",
      "       'temperature_fahrenheit', 'condition_text', 'wind_mph', 'wind_kph',\n",
      "       'wind_degree', 'wind_direction', 'pressure_mb', 'pressure_in',\n",
      "       'precip_mm', 'precip_in', 'humidity', 'cloud', 'feels_like_celsius',\n",
      "       'feels_like_fahrenheit', 'visibility_km', 'visibility_miles',\n",
      "       'uv_index', 'gust_mph', 'gust_kph', 'air_quality_Carbon_Monoxide',\n",
      "       'air_quality_Ozone', 'air_quality_Nitrogen_dioxide',\n",
      "       'air_quality_Sulphur_dioxide', 'air_quality_PM2.5', 'air_quality_PM10',\n",
      "       'air_quality_us-epa-index', 'air_quality_gb-defra-index', 'sunrise',\n",
      "       'sunset', 'moonrise', 'moonset', 'moon_phase', 'moon_illumination'],\n",
      "      dtype='object')\n",
      "Pollution DataFrame columns: Index(['Country', 'City', 'AQI Value', 'AQI Category', 'CO AQI Value',\n",
      "       'CO AQI Category', 'Ozone AQI Value', 'Ozone AQI Category',\n",
      "       'NO2 AQI Value', 'NO2 AQI Category', 'PM2.5 AQI Value',\n",
      "       'PM2.5 AQI Category'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the correct paths for the CSV files\n",
    "aqi_file_path = '/Users/bellewills/data/data_date.csv'\n",
    "weather_file_path = '/Users/bellewills/data/GlobalWeatherRepository.csv'\n",
    "pollution_file_path = '/Users/bellewills/data/global air pollution dataset.csv'\n",
    "\n",
    "# Load datasets into pandas DataFrames\n",
    "df_aqi = pd.read_csv(aqi_file_path)\n",
    "df_weather = pd.read_csv(weather_file_path)\n",
    "df_pollution = pd.read_csv(pollution_file_path)\n",
    "\n",
    "# Print column names to identify correct names\n",
    "print(\"AQI DataFrame columns:\", df_aqi.columns)\n",
    "print(\"Weather DataFrame columns:\", df_weather.columns)\n",
    "print(\"Pollution DataFrame columns:\", df_pollution.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9c5029-d6c5-4603-90b0-a4984c2e86cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d6db811-8367-4dee-82b9-dddb8e75640d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AQI DataFrame:\n",
      "         Date    Country                          Status  AQI Value\n",
      "0  2022-07-21    Albania                            Good         14\n",
      "1  2022-07-21    Algeria                        Moderate         65\n",
      "2  2022-07-21    Andorra                        Moderate         55\n",
      "3  2022-07-21     Angola  Unhealthy for Sensitive Groups        113\n",
      "4  2022-07-21  Argentina                        Moderate         63\n",
      "\n",
      "Weather DataFrame:\n",
      "       country     location_name  latitude  longitude        timezone  \\\n",
      "0  Afghanistan             Kabul     34.52      69.18      Asia/Kabul   \n",
      "1      Albania            Tirana     41.33      19.82   Europe/Tirane   \n",
      "2      Algeria           Algiers     36.76       3.05  Africa/Algiers   \n",
      "3      Andorra  Andorra La Vella     42.50       1.52  Europe/Andorra   \n",
      "4       Angola            Luanda     -8.84      13.23   Africa/Luanda   \n",
      "\n",
      "   last_updated_epoch      last_updated  temperature_celsius  \\\n",
      "0          1715849100  2024-05-16 13:15                 26.6   \n",
      "1          1715849100  2024-05-16 10:45                 19.0   \n",
      "2          1715849100  2024-05-16 09:45                 23.0   \n",
      "3          1715849100  2024-05-16 10:45                  6.3   \n",
      "4          1715849100  2024-05-16 09:45                 26.0   \n",
      "\n",
      "   temperature_fahrenheit condition_text  ...  air_quality_PM2.5  \\\n",
      "0                    79.8  Partly Cloudy  ...                8.4   \n",
      "1                    66.2  Partly cloudy  ...                1.1   \n",
      "2                    73.4          Sunny  ...               10.4   \n",
      "3                    43.3  Light drizzle  ...                0.7   \n",
      "4                    78.8  Partly cloudy  ...              183.4   \n",
      "\n",
      "   air_quality_PM10  air_quality_us-epa-index air_quality_gb-defra-index  \\\n",
      "0              26.6                         1                          1   \n",
      "1               2.0                         1                          1   \n",
      "2              18.4                         1                          1   \n",
      "3               0.9                         1                          1   \n",
      "4             262.3                         5                         10   \n",
      "\n",
      "    sunrise    sunset  moonrise   moonset      moon_phase  moon_illumination  \n",
      "0  04:50 AM  06:50 PM  12:12 PM  01:11 AM  Waxing Gibbous                 55  \n",
      "1  05:21 AM  07:54 PM  12:58 PM  02:14 AM  Waxing Gibbous                 55  \n",
      "2  05:40 AM  07:50 PM  01:15 PM  02:14 AM  Waxing Gibbous                 55  \n",
      "3  06:31 AM  09:11 PM  02:12 PM  03:31 AM  Waxing Gibbous                 55  \n",
      "4  06:12 AM  05:55 PM  01:17 PM  12:38 AM  Waxing Gibbous                 55  \n",
      "\n",
      "[5 rows x 41 columns]\n",
      "\n",
      "Pollution DataFrame:\n",
      "              Country              City  AQI Value AQI Category  CO AQI Value  \\\n",
      "0  Russian Federation        Praskoveya         51     Moderate             1   \n",
      "1              Brazil  Presidente Dutra         41         Good             1   \n",
      "2               Italy   Priolo Gargallo         66     Moderate             1   \n",
      "3              Poland         Przasnysz         34         Good             1   \n",
      "4              France          Punaauia         22         Good             0   \n",
      "\n",
      "  CO AQI Category  Ozone AQI Value Ozone AQI Category  NO2 AQI Value  \\\n",
      "0            Good               36               Good              0   \n",
      "1            Good                5               Good              1   \n",
      "2            Good               39               Good              2   \n",
      "3            Good               34               Good              0   \n",
      "4            Good               22               Good              0   \n",
      "\n",
      "  NO2 AQI Category  PM2.5 AQI Value PM2.5 AQI Category  \n",
      "0             Good               51           Moderate  \n",
      "1             Good               41               Good  \n",
      "2             Good               66           Moderate  \n",
      "3             Good               20               Good  \n",
      "4             Good                6               Good  \n",
      "\n",
      "Locations DataFrame:\n",
      "     country city  latitude  longitude  location_id\n",
      "0    Albania  NaN       NaN        NaN            1\n",
      "1    Algeria  NaN       NaN        NaN            2\n",
      "2    Andorra  NaN       NaN        NaN            3\n",
      "3     Angola  NaN       NaN        NaN            4\n",
      "4  Argentina  NaN       NaN        NaN            5\n"
     ]
    },
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql '\n        SELECT\n            name\n        FROM\n            sqlite_master\n        WHERE\n            type IN ('table', 'view')\n            AND name=?;\n        ': database is locked",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/flaskenv/lib/python3.12/site-packages/pandas/io/sql.py:2674\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2674\u001b[0m     cur\u001b[38;5;241m.\u001b[39mexecute(sql, \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   2675\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cur\n",
      "\u001b[0;31mOperationalError\u001b[0m: database is locked",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 50\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_locations\u001b[38;5;241m.\u001b[39mhead())\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Save locations to the SQL table\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m df_locations\u001b[38;5;241m.\u001b[39mto_sql(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocations\u001b[39m\u001b[38;5;124m'\u001b[39m, conn, if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Create and populate the parameters table\u001b[39;00m\n\u001b[1;32m     53\u001b[0m parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(df_pollution\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m2\u001b[39m:])\u001b[38;5;241m.\u001b[39munion({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAQI\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTemperature\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "File \u001b[0;32m~/anaconda3/envs/flaskenv/lib/python3.12/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/flaskenv/lib/python3.12/site-packages/pandas/core/generic.py:3087\u001b[0m, in \u001b[0;36mNDFrame.to_sql\u001b[0;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[1;32m   2889\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2890\u001b[0m \u001b[38;5;124;03mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[1;32m   2891\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3083\u001b[0m \u001b[38;5;124;03m[(1,), (None,), (2,)]\u001b[39;00m\n\u001b[1;32m   3084\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m   3085\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sql\n\u001b[0;32m-> 3087\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sql\u001b[38;5;241m.\u001b[39mto_sql(\n\u001b[1;32m   3088\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   3089\u001b[0m     name,\n\u001b[1;32m   3090\u001b[0m     con,\n\u001b[1;32m   3091\u001b[0m     schema\u001b[38;5;241m=\u001b[39mschema,\n\u001b[1;32m   3092\u001b[0m     if_exists\u001b[38;5;241m=\u001b[39mif_exists,\n\u001b[1;32m   3093\u001b[0m     index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[1;32m   3094\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[1;32m   3095\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[1;32m   3096\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   3097\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m   3098\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/flaskenv/lib/python3.12/site-packages/pandas/io/sql.py:842\u001b[0m, in \u001b[0;36mto_sql\u001b[0;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[1;32m    837\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    838\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m argument should be either a Series or a DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    839\u001b[0m     )\n\u001b[1;32m    841\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con, schema\u001b[38;5;241m=\u001b[39mschema, need_transaction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[0;32m--> 842\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mto_sql(\n\u001b[1;32m    843\u001b[0m         frame,\n\u001b[1;32m    844\u001b[0m         name,\n\u001b[1;32m    845\u001b[0m         if_exists\u001b[38;5;241m=\u001b[39mif_exists,\n\u001b[1;32m    846\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[1;32m    847\u001b[0m         index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[1;32m    848\u001b[0m         schema\u001b[38;5;241m=\u001b[39mschema,\n\u001b[1;32m    849\u001b[0m         chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[1;32m    850\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    851\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    852\u001b[0m         engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[1;32m    853\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mengine_kwargs,\n\u001b[1;32m    854\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/flaskenv/lib/python3.12/site-packages/pandas/io/sql.py:2850\u001b[0m, in \u001b[0;36mSQLiteDatabase.to_sql\u001b[0;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[1;32m   2839\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmy_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) not a string\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2841\u001b[0m table \u001b[38;5;241m=\u001b[39m SQLiteTable(\n\u001b[1;32m   2842\u001b[0m     name,\n\u001b[1;32m   2843\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2848\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   2849\u001b[0m )\n\u001b[0;32m-> 2850\u001b[0m table\u001b[38;5;241m.\u001b[39mcreate()\n\u001b[1;32m   2851\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m table\u001b[38;5;241m.\u001b[39minsert(chunksize, method)\n",
      "File \u001b[0;32m~/anaconda3/envs/flaskenv/lib/python3.12/site-packages/pandas/io/sql.py:984\u001b[0m, in \u001b[0;36mSQLTable.create\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 984\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexists():\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mif_exists \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfail\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    986\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTable \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m already exists.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/flaskenv/lib/python3.12/site-packages/pandas/io/sql.py:970\u001b[0m, in \u001b[0;36mSQLTable.exists\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexists\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 970\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpd_sql\u001b[38;5;241m.\u001b[39mhas_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschema)\n",
      "File \u001b[0;32m~/anaconda3/envs/flaskenv/lib/python3.12/site-packages/pandas/io/sql.py:2865\u001b[0m, in \u001b[0;36mSQLiteDatabase.has_table\u001b[0;34m(self, name, schema)\u001b[0m\n\u001b[1;32m   2854\u001b[0m wld \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2855\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m   2856\u001b[0m \u001b[38;5;124mSELECT\u001b[39m\n\u001b[1;32m   2857\u001b[0m \u001b[38;5;124m    name\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2862\u001b[0m \u001b[38;5;124m    AND name=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwld\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m;\u001b[39m\n\u001b[1;32m   2863\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m-> 2865\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(query, [name])\u001b[38;5;241m.\u001b[39mfetchall()) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/flaskenv/lib/python3.12/site-packages/pandas/io/sql.py:2686\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2683\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minner_exc\u001b[39;00m\n\u001b[1;32m   2685\u001b[0m ex \u001b[38;5;241m=\u001b[39m DatabaseError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution failed on sql \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msql\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2686\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mDatabaseError\u001b[0m: Execution failed on sql '\n        SELECT\n            name\n        FROM\n            sqlite_master\n        WHERE\n            type IN ('table', 'view')\n            AND name=?;\n        ': database is locked"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Paths to your CSV files\n",
    "aqi_file_path = '/Users/bellewills/data/data_date.csv'\n",
    "weather_file_path = '/Users/bellewills/data/GlobalWeatherRepository.csv'\n",
    "pollution_file_path = '/Users/bellewills/data/global air pollution dataset.csv'\n",
    "\n",
    "# Load datasets into pandas DataFrames\n",
    "df_aqi = pd.read_csv(aqi_file_path)\n",
    "df_weather = pd.read_csv(weather_file_path)\n",
    "df_pollution = pd.read_csv(pollution_file_path)\n",
    "\n",
    "# Display the loaded data\n",
    "print(\"AQI DataFrame:\")\n",
    "print(df_aqi.head())\n",
    "print(\"\\nWeather DataFrame:\")\n",
    "print(df_weather.head())\n",
    "print(\"\\nPollution DataFrame:\")\n",
    "print(df_pollution.head())\n",
    "\n",
    "# Create a SQLite database\n",
    "conn = sqlite3.connect('aqi_database.db')\n",
    "\n",
    "# Function to list tables in the database\n",
    "def list_tables(conn):\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = [row[0] for row in cursor.fetchall()]\n",
    "    return tables\n",
    "\n",
    "# Create and populate the locations table\n",
    "df_locations_aqi = df_aqi[['Country']].drop_duplicates().reset_index(drop=True)\n",
    "df_locations_weather = df_weather[['country', 'location_name', 'latitude', 'longitude']].drop_duplicates().reset_index(drop=True)\n",
    "df_locations_pollution = df_pollution[['Country', 'City']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "df_locations_aqi.rename(columns={'Country': 'country'}, inplace=True)\n",
    "df_locations_weather.rename(columns={'country': 'country', 'location_name': 'city'}, inplace=True)\n",
    "df_locations_pollution.rename(columns={'Country': 'country', 'City': 'city'}, inplace=True)\n",
    "\n",
    "# Combine all locations into one DataFrame\n",
    "df_locations = pd.concat([df_locations_aqi, df_locations_weather[['country', 'city', 'latitude', 'longitude']], df_locations_pollution[['country', 'city']]]).drop_duplicates().reset_index(drop=True)\n",
    "df_locations['location_id'] = df_locations.index + 1\n",
    "\n",
    "# Display the locations DataFrame\n",
    "print(\"\\nLocations DataFrame:\")\n",
    "print(df_locations.head())\n",
    "\n",
    "# Save locations to the SQL table\n",
    "df_locations.to_sql('locations', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Create and populate the parameters table\n",
    "parameters = set(df_pollution.columns[2:]).union({'AQI', 'Temperature'})\n",
    "df_parameters = pd.DataFrame(parameters, columns=['parameter'])\n",
    "df_parameters['parameter_id'] = df_parameters.index + 1\n",
    "\n",
    "# Remove any null entries\n",
    "df_parameters = df_parameters.dropna()\n",
    "\n",
    "# Display the parameters DataFrame\n",
    "print(\"\\nParameters DataFrame:\")\n",
    "print(df_parameters.head())\n",
    "\n",
    "df_parameters.to_sql('parameters', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Create and populate the measurements table\n",
    "df_measurements_aqi = df_aqi[['Country', 'Date', 'AQI Value']].copy()\n",
    "df_measurements_aqi.rename(columns={'Country': 'country', 'Date': 'date', 'AQI Value': 'value'}, inplace=True)\n",
    "df_measurements_aqi['parameter'] = 'AQI'\n",
    "df_measurements_aqi['source'] = 'aqi'\n",
    "\n",
    "df_measurements_weather = df_weather[['country', 'location_name', 'temperature_celsius', 'last_updated']].copy()\n",
    "df_measurements_weather.rename(columns={'country': 'country', 'location_name': 'city', 'temperature_celsius': 'value', 'last_updated': 'date'}, inplace=True)\n",
    "df_measurements_weather['parameter'] = 'Temperature'\n",
    "df_measurements_weather['source'] = 'weather'\n",
    "\n",
    "df_measurements_pollution = df_pollution.melt(id_vars=['Country', 'City'], var_name='parameter', value_name='value').copy()\n",
    "df_measurements_pollution.rename(columns={'Country': 'country', 'City': 'city'}, inplace=True)\n",
    "df_measurements_pollution['source'] = 'pollution'\n",
    "\n",
    "df_measurements = pd.concat([df_measurements_aqi, df_measurements_weather, df_measurements_pollution]).drop_duplicates().reset_index(drop=True)\n",
    "df_measurements = df_measurements.merge(df_locations[['location_id', 'country', 'city']], on=['country', 'city'])\n",
    "\n",
    "# Merge parameter_id into measurements\n",
    "df_measurements = df_measurements.merge(df_parameters[['parameter_id', 'parameter']], on='parameter')\n",
    "\n",
    "df_measurements['id'] = df_measurements.index + 1  # Add ID column\n",
    "\n",
    "# Display the measurements DataFrame\n",
    "print(\"\\nMeasurements DataFrame:\")\n",
    "print(df_measurements.head())\n",
    "\n",
    "df_measurements.to_sql('measurements', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Verify the tables in the database\n",
    "tables = list_tables(conn)\n",
    "print(\"\\nTables in the database:\", tables)\n",
    "\n",
    "# Display the first few rows of each table\n",
    "for table in tables:\n",
    "    query = f\"SELECT * FROM {table} LIMIT 5;\"\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    print(f\"\\nPreview of {table} table:\")\n",
    "    print(df)\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cafc0bdd-8f95-4c45-8c9d-6544df37fc9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "database is locked",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# List all tables in the database\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m tables \u001b[38;5;241m=\u001b[39m list_tables(conn)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTables in the database:\u001b[39m\u001b[38;5;124m\"\u001b[39m, tables)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Preview each table\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[24], line 10\u001b[0m, in \u001b[0;36mlist_tables\u001b[0;34m(conn)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlist_tables\u001b[39m(conn):\n\u001b[1;32m      9\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT name FROM sqlite_master WHERE type=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 10\u001b[0m     result \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mexecute(query)\u001b[38;5;241m.\u001b[39mfetchall()\n\u001b[1;32m     11\u001b[0m     tables \u001b[38;5;241m=\u001b[39m [row[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m result]\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tables\n",
      "\u001b[0;31mOperationalError\u001b[0m: database is locked"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect('aqi_database.db')\n",
    "\n",
    "# Function to list all tables\n",
    "def list_tables(conn):\n",
    "    query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "    result = conn.execute(query).fetchall()\n",
    "    tables = [row[0] for row in result]\n",
    "    return tables\n",
    "\n",
    "# Function to get a preview of a table\n",
    "def preview_table(conn, table_name, limit=5):\n",
    "    query = f\"SELECT * FROM {table_name} LIMIT {limit};\"\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    return df\n",
    "\n",
    "# List all tables in the database\n",
    "tables = list_tables(conn)\n",
    "print(\"Tables in the database:\", tables)\n",
    "\n",
    "# Preview each table\n",
    "for table in tables:\n",
    "    print(f\"\\nPreview of {table} table:\")\n",
    "    print(preview_table(conn, table))\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43b2820-7dbe-4f25-b8d2-8337764508be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# decided not to use aqitable.db - tried using two db together but kept getting database is locked error for aqitable.db \n",
    "# - so only using aqi_database.db\n",
    "\n",
    "# import sqlite3\n",
    "# import pandas as pd\n",
    "# import time\n",
    "\n",
    "# # Function to update the measurements table with retry logic and exponential backoff\n",
    "# def update_measurements(conn_main, row):\n",
    "#     retries = 5\n",
    "#     delay = 1  # initial delay in seconds\n",
    "#     while retries > 0:\n",
    "#         try:\n",
    "#             conn_main.execute('''\n",
    "#                 UPDATE measurements \n",
    "#                 SET status = ?, value = ?\n",
    "#                 WHERE location_id = ? AND date = ?\n",
    "#             ''', (row['Status'], row['AQI Value'], row['location_id'], row['Date']))\n",
    "#             conn_main.commit()\n",
    "#             break\n",
    "#         except sqlite3.OperationalError as e:\n",
    "#             if 'database is locked' in str(e):\n",
    "#                 retries -= 1\n",
    "#                 time.sleep(delay)\n",
    "#                 delay *= 2  # exponential backoff - got this part off google to try and help with the database is locked error but didnt work\n",
    "#                 if retries == 0:\n",
    "#                     raise\n",
    "#             else:\n",
    "#                 raise\n",
    "\n",
    "# # Connect to the main database and the second database with a timeout\n",
    "# conn_main = sqlite3.connect('aqi_database.db', timeout=30)\n",
    "# conn_second = sqlite3.connect('aqi.db')\n",
    "\n",
    "# # Load data from the second database\n",
    "# query = \"SELECT Date, Country, Status, `AQI Value` FROM aqitable\"\n",
    "# aqi_data = pd.read_sql_query(query, conn_second)\n",
    "\n",
    "# # Load the location mapping from the main database\n",
    "# location_mapping = pd.read_sql_query('SELECT location_id, country FROM locations', conn_main)\n",
    "\n",
    "# # Merge the AQI data with the location mapping\n",
    "# merged_data = pd.merge(aqi_data, location_mapping, left_on='Country', right_on='country', how='left')\n",
    "\n",
    "# # Update the measurements table with the status and AQI Value data\n",
    "# for index, row in merged_data.iterrows():\n",
    "#     update_measurements(conn_main, row)\n",
    "\n",
    "# # Close the connections\n",
    "# conn_main.close()\n",
    "# conn_second.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8610ee0a-ebb4-4d23-b2e1-26385819d9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a5cd09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13b42d9-2269-4bd5-8a3c-ba0b6cedf5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install sqlalchemy\n",
    "%pip install flask_cors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7daf8263",
   "metadata": {},
   "source": [
    "# START SERVER!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e19b049-1bec-490c-8d68-4a015cdde2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, jsonify, render_template\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine, text\n",
    "from flask_cors import CORS\n",
    "import time\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)  # Enable CORS for all routes\n",
    "\n",
    "# SQLAlchemy setup with increased timeout\n",
    "db_uri = \"sqlite:///aqi_database.db\"  # Database URI for SQLite\n",
    "engine = create_engine(db_uri, connect_args={'timeout': 30})\n",
    "\n",
    "@app.route(\"/\")\n",
    "def hello_world():\n",
    "    \"\"\"\n",
    "    Route for the home page.\n",
    "    \"\"\"\n",
    "    return \"\"\"\n",
    "        <h1> Air Quality Database</h1>\n",
    "        <p>Follow the link to <a href=\"/locations\">locations</a>.</p>\n",
    "    \"\"\"\n",
    "\n",
    "@app.route(\"/locations\")\n",
    "def list_locations():\n",
    "    \"\"\"\n",
    "    Route to list all locations.\n",
    "    \"\"\"\n",
    "    retries = 5\n",
    "    while retries > 0:\n",
    "        try:\n",
    "            with engine.connect() as connection:\n",
    "                result = connection.execute(text(\"SELECT location_id, country, city, latitude, longitude FROM locations\"))\n",
    "                output = [\"<h1>List of Locations</h1>\", \"<ul>\"]\n",
    "\n",
    "                for location in result:\n",
    "                    id = location[0]\n",
    "                    country = location[1]\n",
    "                    city = location[2] if location[2] else ''\n",
    "                    latitude = location[3]\n",
    "                    longitude = location[4]\n",
    "                    output.append(f\"\"\"\n",
    "                        <li>\n",
    "                            {country} - {city} (Lat: {latitude}, Long: {longitude}): \n",
    "                            <a href=\"/parameters/{id}\">Parameters</a>\n",
    "                            - <a href=\"/measurements/{id}\">Measurements Data</a>\n",
    "                        </li>\"\"\"\n",
    "                    )\n",
    "\n",
    "                output.append(\"</ul>\")\n",
    "                return \"\\n\".join(output)\n",
    "        except sqlalchemy.exc.OperationalError as e:\n",
    "            if 'database is locked' in str(e):\n",
    "                retries -= 1\n",
    "                time.sleep(2)  # Wait for 2 seconds before retrying\n",
    "            else:\n",
    "                raise\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            return jsonify({\"error\": \"Error fetching locations\"}), 500\n",
    "\n",
    "def get_location_name(session, id):\n",
    "    \"\"\"\n",
    "    Function to get the name of a location.\n",
    "    \"\"\"\n",
    "    result = session.execute(text(\"SELECT country, city FROM locations WHERE location_id = :id\"), {\"id\": id})\n",
    "    location = result.first()\n",
    "    return f\"{location[0]} - {location[1]}\" if location[1] else location[0]\n",
    "\n",
    "@app.route(\"/parameters/<int:location_id>\")\n",
    "def list_parameters(location_id):\n",
    "    \"\"\"\n",
    "    Route to list parameters for a given location.\n",
    "    \"\"\"\n",
    "    retries = 5\n",
    "    while retries > 0:\n",
    "        try:\n",
    "            with engine.connect() as connection:\n",
    "                result = connection.execute(text(\"SELECT parameter_id, parameter FROM parameters\"))\n",
    "                location_name = get_location_name(connection, location_id)\n",
    "                output = [\n",
    "                    f\"<h1>Parameters in {location_name}</h1>\",\n",
    "                    \"<ul>\"\n",
    "                ]\n",
    "                for item in result:\n",
    "                    output.append(f\"<li>{item[0]}: {item[1]}</li>\")\n",
    "\n",
    "                output.append(\"</ul>\")\n",
    "                return \"\\n\".join(output)\n",
    "        except sqlalchemy.exc.OperationalError as e:\n",
    "            if 'database is locked' in str(e):\n",
    "                retries -= 1\n",
    "                time.sleep(2)  # Wait for 2 seconds before retrying\n",
    "            else:\n",
    "                raise\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            return jsonify({\"error\": \"Error fetching parameters\"}), 500\n",
    "\n",
    "@app.route(\"/measurements/<int:location_id>\")\n",
    "def list_measurements(location_id):\n",
    "    \"\"\"\n",
    "    Route to list measurements for a given location.\n",
    "    \"\"\"\n",
    "    retries = 5\n",
    "    while retries > 0:\n",
    "        try:\n",
    "            with engine.connect() as connection:\n",
    "                result = connection.execute(text(\"\"\"\n",
    "                    SELECT measurements.id, parameters.parameter, measurements.value, measurements.status, locations.latitude, locations.longitude\n",
    "                    FROM measurements\n",
    "                    JOIN parameters ON measurements.parameter_id = parameters.parameter_id\n",
    "                    JOIN locations ON measurements.location_id = locations.location_id\n",
    "                    WHERE measurements.location_id = :id\n",
    "                \"\"\"), {\"id\": location_id})\n",
    "                location_name = get_location_name(connection, location_id)\n",
    "                output = [\n",
    "                    f\"<h1>Measurements Data for {location_name}</h1>\",\n",
    "                    \"<ul>\"\n",
    "                ]\n",
    "                for item in result:\n",
    "                    output.append(f\"<li>ID: {item[0]}, Parameter: {item[1]}, Value: {item[2]}, Status: {item[3]}, Latitude: {item[4]}, Longitude: {item[5]}</li>\")\n",
    "\n",
    "                output.append(\"</ul>\")\n",
    "                return \"\\n\".join(output)\n",
    "        except sqlalchemy.exc.OperationalError as e:\n",
    "            if 'database is locked' in str(e):\n",
    "                retries -= 1\n",
    "                time.sleep(2)  # Wait for 2 seconds before retrying\n",
    "            else:\n",
    "                raise\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            return jsonify({\"error\": \"Error fetching measurements\"}), 500\n",
    "\n",
    "@app.route(\"/json/locations\")\n",
    "def json_list_locations():\n",
    "    \"\"\"\n",
    "    Route to list all locations in JSON format.\n",
    "    \"\"\"\n",
    "    retries = 5\n",
    "    while retries > 0:\n",
    "        try:\n",
    "            with engine.connect() as connection:\n",
    "                result = connection.execute(text(\"SELECT location_id, country, city, latitude, longitude FROM locations\"))\n",
    "                data = [{'id': location[0], 'country': location[1], 'city': location[2], 'latitude': location[3], 'longitude': location[4]} for location in result]\n",
    "                return jsonify(data=data)\n",
    "        except sqlalchemy.exc.OperationalError as e:\n",
    "            if 'database is locked' in str(e):\n",
    "                retries -= 1\n",
    "                time.sleep(2)  # Wait for 2 seconds before retrying\n",
    "            else:\n",
    "                raise\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            return jsonify({\"error\": \"Error fetching locations\"}), 500\n",
    "\n",
    "@app.route(\"/json/location/<int:location_id>/parameters\")\n",
    "def json_location_parameters(location_id):\n",
    "    \"\"\"\n",
    "    Route to list parameters for a given location in JSON format.\n",
    "    \"\"\"\n",
    "    retries = 5\n",
    "    while retries > 0:\n",
    "        try:\n",
    "            with engine.connect() as connection:\n",
    "                result = connection.execute(text(\"SELECT parameter_id, parameter FROM parameters\"))\n",
    "                data = [{'id': parameter[0], 'name': parameter[1]} for parameter in result]\n",
    "                return jsonify(data=data)\n",
    "        except sqlalchemy.exc.OperationalError as e:\n",
    "            if 'database is locked' in str(e):\n",
    "                retries -= 1\n",
    "                time.sleep(2)  # Wait for 2 seconds before retrying\n",
    "            else:\n",
    "                raise\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            return jsonify({\"error\": \"Error fetching parameters\"}), 500\n",
    "\n",
    "@app.route(\"/json/location/<int:location_id>/measurements\")\n",
    "def json_location_measurements(location_id):\n",
    "    \"\"\"\n",
    "    Route to list measurements for a given location in JSON format.\n",
    "    \"\"\"\n",
    "    retries = 5\n",
    "    while retries > 0:\n",
    "        try:\n",
    "            with engine.connect() as connection:\n",
    "                result = connection.execute(text(\"\"\"\n",
    "                    SELECT measurements.id, parameters.parameter, measurements.value, measurements.date, measurements.location_id, measurements.parameter_id\n",
    "                    FROM measurements\n",
    "                    JOIN parameters ON measurements.parameter_id = parameters.parameter_id\n",
    "                    WHERE measurements.location_id = :id\n",
    "                \"\"\"), {\"id\": location_id})\n",
    "                data = [{'id': measurement['id'], 'parameter': measurement['parameter'], 'value': measurement['value'], 'date': measurement['date'], 'location_id': measurement['location_id'], 'parameter_id': measurement['parameter_id']} for measurement in result]\n",
    "                return jsonify(data=data)\n",
    "        except sqlalchemy.exc.OperationalError as e:\n",
    "            if 'database is locked' in str(e):\n",
    "                retries -= 1\n",
    "                time.sleep(2)  # Wait for 2 seconds before retrying\n",
    "            else:\n",
    "                raise\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            return jsonify({\"error\": \"Error fetching measurements\"}), 500\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=False, port=5100)  # Make sure debug is off!!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7ff54d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecdab52-fe6e-476f-8671-a6ac267c5d7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
